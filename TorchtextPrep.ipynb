{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TorchtextPrep.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9mF7WKwS4UIeD/wwRjgrZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedahmadian/MYNLP/blob/main/TorchtextPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L3WtA2yARsH",
        "outputId": "01650ad4-be3c-4b6c-e4bf-691daeea6776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "source": [
        " !python -m spacy download en_core_web_md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp36-none-any.whl size=98051305 sha256=de359c89588545849b931b618e627bd9792037a3f0750c15683d36ab0926ffdb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1k0l_v2y/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aghj4tiy_d13"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize \n",
        "import spacy\n",
        "import torch\n",
        "import torchtext\n",
        "import en_core_web_md\n",
        "nlp= en_core_web_md.load()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZV0guhaAGJE",
        "outputId": "3bcd570c-11ee-440c-81ad-26fc52f656ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "import pandas as pd\n",
        "df_train=pd.read_csv('train.csv',header='infer')\n",
        "df_train.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "5  00025465d4725e87  ...             0\n",
              "6  0002bcb3da6cb337  ...             0\n",
              "7  00031b1e95af7921  ...             0\n",
              "8  00037261f536c51d  ...             0\n",
              "9  00040093b2687caa  ...             0\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti14q7lEBl7P",
        "outputId": "94db029c-be15-4110-ac78-8b6346152c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\"Use any of the spacy or nltk methods in any level\"\n",
        "\"here I use nltk\"\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "stop_words=nltk.corpus.stopwords.words('english')\n",
        "stop_words.remove('not')\n",
        "def CustomTokenizerSpacy(sentence):\n",
        "    sentence= re.sub('n\\'t',r' not',sentence)\n",
        "    sentence=re.sub(r'[^a-zA-Z0-9!?,\\.]',' ',sentence)\n",
        "    sentence= re.sub(r'([\\?!,\\.]+)',lambda m: m.group(1)[0],sentence)\n",
        "    sentence=re.sub(r'[ ]+',' ',sentence)\n",
        "    return [token.lemma_ for token in nlp.tokenizer(sentence) if token.lemma_ not in nlp.Defaults.stop_words]# \n",
        "\n",
        "def CustomTokenizerNltk(sentence):\n",
        "    sentence=  re.sub(r'[^a-zA-Z0-9!?,\\.\\']',' ',sentence)\n",
        "    sentence= re.sub(r'([\\?!,\\.]+)',lambda m: m.group(1)[0],sentence)\n",
        "    sentence=re.sub(r'[ ]+',' ',sentence)\n",
        "    sentence= re.sub('n\\'t',r' not',sentence)\n",
        "#     stemmer=nltk.stem.WordNetLemmatizer()\n",
        "    stemmer= nltk.stem.PorterStemmer()\n",
        "    return [stemmer.stem(token) for token in nltk.tokenize.word_tokenize(sentence) if token not in stop_words]\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLZNvgaXe74Q",
        "outputId": "49f40d95-6043-476e-b19d-9f36a8201aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# To use the ReversibleField we need to install reverse tokenizer\n",
        "!git clone https://github.com/jekbradbury/revtok.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'revtok'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Total 145 (delta 0), reused 0 (delta 0), pack-reused 145\u001b[K\n",
            "Receiving objects: 100% (145/145), 60.97 KiB | 4.06 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0Gk7rMdhLS6",
        "outputId": "bc6cb258-2a74-4af4-ad04-3815d13bc021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        }
      },
      "source": [
        "!python revtok/setup.py install "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating revtok.egg-info\n",
            "writing revtok.egg-info/PKG-INFO\n",
            "writing dependency_links to revtok.egg-info/dependency_links.txt\n",
            "writing requirements to revtok.egg-info/requires.txt\n",
            "writing top-level names to revtok.egg-info/top_level.txt\n",
            "writing manifest file 'revtok.egg-info/SOURCES.txt'\n",
            "reading manifest file 'revtok.egg-info/SOURCES.txt'\n",
            "writing manifest file 'revtok.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying revtok.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying revtok.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying revtok.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying revtok.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying revtok.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/revtok-0.0.3-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing revtok-0.0.3-py3.6.egg\n",
            "Copying revtok-0.0.3-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding revtok 0.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/revtok-0.0.3-py3.6.egg\n",
            "Processing dependencies for revtok==0.0.3\n",
            "Finished processing dependencies for revtok==0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MVOox9zB7_J"
      },
      "source": [
        "from torchtext.data import Field,ReversibleField\n",
        "# comment_text= Field(sequential=True,use_vocab=True,\n",
        "#                     lower=True,batch_first=True\n",
        "#                    ,tokenize=CustomTokenizerSpacy\n",
        "#                    ) # we don use use_vocab=True because we are using our own toeknizer\n",
        "\n",
        "comment_text= ReversibleField(sequential=True,use_vocab=True,\n",
        "                    lower=True,batch_first=True\n",
        "                   ,tokenize=CustomTokenizerSpacy\n",
        "                   ) # we don use use_vocab=True because we are using our own toeknizer\n",
        "toxic= Field(sequential=False,use_vocab=False)\n",
        "severe_toxic= Field(sequential=False,use_vocab=False)\n",
        "obscene= Field(sequential=False,use_vocab=False)\n",
        "threat= Field(sequential=False,use_vocab=False)\n",
        "insult= Field(sequential=False,use_vocab=False)\n",
        "identity_hate= Field(sequential=False,use_vocab=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nUYDBHtCIX0"
      },
      "source": [
        "from torchtext.data import TabularDataset\n",
        "train_datafields=[('id',None),('comment_text',comment_text),('toxic',toxic),('severe_toxic',severe_toxic),\n",
        "                 ('obscene',obscene),('threat',threat),('insult',insult),('identity_hate',identity_hate)]\n",
        "train_set= TabularDataset(path='train.csv',format='csv',fields=train_datafields,skip_header=False)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyd1Cn-0CMb_",
        "outputId": "7e832bbf-35c1-4c5d-ca56-ee74bd7293bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# comment_text.build_vocab(train_set,vectors=\"glove.6B.100d\")\n",
        "comment_text.build_vocab(train_set)\n",
        "len(comment_text.vocab)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7kueT9DC8cb",
        "outputId": "9e5e0214-e29f-479d-d761-31c58406cd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"convert string \\\"go\\\" to integer : {} \".format(comment_text.vocab.stoi['<pad>']))\n",
        "print(\"convert integer to strings : {} \".format(comment_text.vocab.itos[1]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert string \"go\" to integer : 1 \n",
            "convert integer to strings : <pad> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSVVY3eREQZX"
      },
      "source": [
        "from torchtext.data import Iterator,BucketIterator\n",
        "train_iter= Iterator(dataset=train_set,batch_size=1,\n",
        "                           sort_key= lambda x: x.comment_text,shuffle=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgg0LzFZP4pF"
      },
      "source": [
        "batch= next(iter(train_iter))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmOm0OzZtwTC",
        "outputId": "0b0b2104-aaa9-4555-f4d1-55b69a3d446d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "[comment_text.vocab.itos[int(token)] for token in batch.comment_text[0,:]]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " 'hillary',\n",
              " 'rodham',\n",
              " 'clinton',\n",
              " 'request',\n",
              " 'greetings',\n",
              " '!',\n",
              " 'a',\n",
              " 'proposal',\n",
              " 'talk',\n",
              " 'hillary',\n",
              " 'rodham',\n",
              " 'clinton',\n",
              " 'requested',\n",
              " '8',\n",
              " 'change',\n",
              " 'title',\n",
              " 'article',\n",
              " ',',\n",
              " 'hillary',\n",
              " 'rodham',\n",
              " 'clinton',\n",
              " 'hillary',\n",
              " 'clinton',\n",
              " '.',\n",
              " 'this',\n",
              " 'notification',\n",
              " 'provide',\n",
              " 'wikipedia',\n",
              " 'canvassing',\n",
              " 'appropriate',\n",
              " 'notification',\n",
              " ',',\n",
              " 'previously',\n",
              " 'participate',\n",
              " 'discussion',\n",
              " 'subject',\n",
              " '.',\n",
              " 'cheers',\n",
              " '!',\n",
              " 't']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D84elHOptxYD"
      },
      "source": [
        "# code from http://nlp.seas.harvard.edu/2018/04/03/attention.html \n",
        "# read text after for description of what it does\n",
        "global max_src_in_batch, max_tgt_in_batch\n",
        "def batch_size_fn(new, count, sofar):\n",
        "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
        "    global max_src_in_batch, max_tgt_in_batch\n",
        "    if count == 1:\n",
        "        max_src_in_batch = 0\n",
        "        max_tgt_in_batch = 0\n",
        "    max_src_in_batch = max(max_src_in_batch,  len(new.English))\n",
        "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.French) + 2)\n",
        "    src_elements = count * max_src_in_batch\n",
        "    tgt_elements = count * max_tgt_in_batch\n",
        "    return max(src_elements, tgt_elements)\n",
        "class MyIterator(data.Iterator):\n",
        "    def create_batches(self):\n",
        "        if self.train:\n",
        "            def pool(d, random_shuffler):\n",
        "                for p in data.batch(d, self.batch_size * 100):\n",
        "                    p_batch = data.batch(\n",
        "                        sorted(p, key=self.sort_key),\n",
        "                        self.batch_size, self.batch_size_fn)\n",
        "                    for b in random_shuffler(list(p_batch)):\n",
        "                        yield b\n",
        "            self.batches = pool(self.data(), self.random_shuffler)\n",
        "            \n",
        "        else:\n",
        "            self.batches = []\n",
        "            for b in data.batch(self.data(), self.batch_size,\n",
        "                                          self.batch_size_fn):\n",
        "                self.batches.append(sorted(b, key=self.sort_key))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}